{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import building, training, models, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'callbacks' from '/home/sergeymiller1996/docs/alissa/callbacks.py'>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(building)\n",
    "reload(training)\n",
    "reload(models)\n",
    "reload(callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "context1 (InputLayer)           (None, 40, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context2 (InputLayer)           (None, 40, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context3 (InputLayer)           (None, 40, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context4 (InputLayer)           (None, 40, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_80 (Model)                (None, 512)          845184      context1[0][0]                   \n",
      "                                                                 context2[0][0]                   \n",
      "                                                                 context3[0][0]                   \n",
      "                                                                 context4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 2048)         0           model_80[1][0]                   \n",
      "                                                                 model_80[2][0]                   \n",
      "                                                                 model_80[3][0]                   \n",
      "                                                                 model_80[4][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 512)          1049088     concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_171 (LeakyReLU)     (None, 512)          0           dense_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 512)          0           leaky_re_lu_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 512)          262656      dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_172 (LeakyReLU)     (None, 512)          0           dense_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "model_81 (Model)                (None, 40, 300)      843436      model_80[3][0]                   \n",
      "                                                                 model_80[4][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "class_out (Dense)               (None, 1)            513         leaky_re_lu_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "auto3 (Lambda)                  (None, 40, 300)      0           model_81[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "auto4 (Lambda)                  (None, 40, 300)      0           model_81[2][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,000,877\n",
      "Trainable params: 3,000,109\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.model((40, 300))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = building.make_emb('datasets/ru.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/sents/train_sents')\n",
    "val = pd.read_csv('datasets/sents/val_sents')\n",
    "train = train.fillna('')\n",
    "val = val.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275027354274464</td>\n",
       "      <td>адем , в конце концов я не принимала участия в...</td>\n",
       "      <td>это точно .</td>\n",
       "      <td>а ты имеешь , самое непосредственное отношение...</td>\n",
       "      <td>0</td>\n",
       "      <td>все были весьма впечатлены твоей презентацией .</td>\n",
       "      <td>good</td>\n",
       "      <td>0.947139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275027354274464</td>\n",
       "      <td>адем , в конце концов я не принимала участия в...</td>\n",
       "      <td>это точно .</td>\n",
       "      <td>а ты имеешь , самое непосредственное отношение...</td>\n",
       "      <td>1</td>\n",
       "      <td>нет . я не знала , что всё это связано .</td>\n",
       "      <td>good</td>\n",
       "      <td>0.882188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275027354274464</td>\n",
       "      <td>адем , в конце концов я не принимала участия в...</td>\n",
       "      <td>это точно .</td>\n",
       "      <td>а ты имеешь , самое непосредственное отношение...</td>\n",
       "      <td>2</td>\n",
       "      <td>но стоило тебе прийти . и она дает тебе заколк...</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.749163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>275027354274464</td>\n",
       "      <td>адем , в конце концов я не принимала участия в...</td>\n",
       "      <td>это точно .</td>\n",
       "      <td>а ты имеешь , самое непосредственное отношение...</td>\n",
       "      <td>3</td>\n",
       "      <td>учитывая , что у тебя не было особой заинтерес...</td>\n",
       "      <td>good</td>\n",
       "      <td>0.865382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275027354274464</td>\n",
       "      <td>адем , в конце концов я не принимала участия в...</td>\n",
       "      <td>это точно .</td>\n",
       "      <td>а ты имеешь , самое непосредственное отношение...</td>\n",
       "      <td>4</td>\n",
       "      <td>и я не должна была подталкивать тебя ко всем э...</td>\n",
       "      <td>good</td>\n",
       "      <td>0.621098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                                                  1  \\\n",
       "0  275027354274464  адем , в конце концов я не принимала участия в...   \n",
       "1  275027354274464  адем , в конце концов я не принимала участия в...   \n",
       "2  275027354274464  адем , в конце концов я не принимала участия в...   \n",
       "3  275027354274464  адем , в конце концов я не принимала участия в...   \n",
       "4  275027354274464  адем , в конце концов я не принимала участия в...   \n",
       "\n",
       "             2                                                  3  4  \\\n",
       "0  это точно .  а ты имеешь , самое непосредственное отношение...  0   \n",
       "1  это точно .  а ты имеешь , самое непосредственное отношение...  1   \n",
       "2  это точно .  а ты имеешь , самое непосредственное отношение...  2   \n",
       "3  это точно .  а ты имеешь , самое непосредственное отношение...  3   \n",
       "4  это точно .  а ты имеешь , самое непосредственное отношение...  4   \n",
       "\n",
       "                                                   5     6         7  \n",
       "0    все были весьма впечатлены твоей презентацией .  good  0.947139  \n",
       "1           нет . я не знала , что всё это связано .  good  0.882188  \n",
       "2  но стоило тебе прийти . и она дает тебе заколк...   bad  0.749163  \n",
       "3  учитывая , что у тебя не было особой заинтерес...  good  0.865382  \n",
       "4  и я не должна была подталкивать тебя ко всем э...  good  0.621098  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7876, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(train, val, emb, epochs=20, batch_size=128, sample_len=10000, load_file=None, save_file=None):\n",
    "    if load_file is None:\n",
    "        model = models.model((40, 300), eps=1e-5)\n",
    "    else:\n",
    "        model = load_model(model_name)\n",
    "\n",
    "        model.compile(\n",
    "                loss=binary_crossentropy,\n",
    "                optimizer=Adadelta,\n",
    "        )\n",
    "        \n",
    "    \n",
    "    batch_size=32\n",
    "    \n",
    "    filepath = \"weights/weights.{epoch:02d}-{val_loss:.3f}.hdf5\"\n",
    "    \n",
    "    y_train = (train['6'] == 'good').values\n",
    "    y_val = (val['6'] == 'good').values\n",
    "    w_train = train['7']\n",
    "    \n",
    "    sample_train = building.shuffle_by_groups(train, '0', random_state=0)[:sample_len]\n",
    "\n",
    "    model.fit_generator(training.flow(train, emb, batch_size, y_train, w_train),\n",
    "                        steps_per_epoch=train.shape[0] / batch_size, \n",
    "                        epochs=epochs, \n",
    "                        shuffle=True,\n",
    "                        callbacks=[callbacks.TelegramCallback(), \n",
    "                                callbacks.RocCallback(sample_train, val, emb),\n",
    "                                callbacks.NDCGCallback(sample_train, val, emb),\n",
    "                                keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9,\n",
    "                              patience=3, min_lr=1e-5),\n",
    "                                keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, \n",
    "                                    save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "                                  ],\n",
    "                        validation_data=training.flow(val, emb, batch_size, y_train),\n",
    "                        validation_steps=val.shape[0] / batch_size,\n",
    "                       )\n",
    "\n",
    "    if save_file is not None:\n",
    "        model.save(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2216/2215 [==============================] - 374s 169ms/step - loss: 1.4145 - class_out_loss: 0.5900 - auto3_loss: 0.8654 - auto4_loss: 0.7446 - val_loss: 1.5295 - val_class_out_loss: 0.7534 - val_auto3_loss: 0.8162 - val_auto4_loss: 0.6977\n",
      "Epoch 2/20\n",
      "1079/2215 [=============>................] - ETA: 3:03 - loss: 1.3156 - class_out_loss: 0.5651 - auto3_loss: 0.7940 - auto4_loss: 0.6655"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-8870eb27177a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-171-9316817538a9>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(train, val, emb, epochs, batch_size, sample_len, load_file, save_file)\u001b[0m\n\u001b[1;32m     34\u001b[0m                                   ],\n\u001b[1;32m     35\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                        )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2191\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_model(train, val, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
